# Step-by-step commands you run (follow this exactly)

# Create project dir & copy files
# Create the folder structure and paste the files above.

# Place your dataset
# Put your dataset at:

data/raw/city_day.csv


# Create venv & install CPU dependencies

python -m venv .venv
source .venv/bin/activate        # on Windows PowerShell: .venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt


# (Optional) Install GPU-enabled libraries — DO THIS ONLY if you enable GPU in params.yaml

# LightGBM (GPU build) — Ubuntu/WSL approach (example):

sudo apt update
sudo apt install -y cmake build-essential libssl-dev libffi-dev python3-dev
git clone --recursive https://github.com/microsoft/LightGBM.git
cd LightGBM
mkdir build && cd build
cmake -DUSE_GPU=ON ..
make -j$(nproc)
# install python package
cd ../python-package
pip install -v .


# XGBoost GPU (conda recommended):

# if using conda
conda create -n xgb python=3.10 -y
conda activate xgb
conda install -c conda-forge py-xgboost
# or build from source with CUDA


# Note: building may require NVIDIA CUDA toolkit & drivers. Use WSL2 GPU docs for Windows.

# Initialize git & DVC

git init
dvc init
dvc add data/raw/city_day.csv
git add data/raw/city_day.csv.dvc .gitignore
git commit -m "Add raw city_day dataset via DVC"


# (Optional) add local DVC remote

mkdir -p /tmp/dvc_store
dvc remote add -d local_remote /tmp/dvc_store
dvc push


# Preprocess

python src/data/preprocess.py
# produces data/processed/city_day_processed.csv


# Train (CPU by default)

python src/models/train.py
# produces model.joblib and MLflow run


# If you want GPU training:

# Set use_gpu: true and gpu_backend: lightgbm (or xgboost) in params.yaml

# Make sure GPU libs installed (see step 4)

# Run: 
python src/models/train.py — it will attempt GPU train and fallback to CPU on error

# View MLflow UI (local)

mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root ./mlflow/mlruns --port 5000
# open http://localhost:5000


# Generate Evidently report

python src/monitoring/evidently_report.py
# open reports/evidently_report.html


# Run Prefect pipeline

python src/prefect/flow.py


# Run API

uvicorn src.api.app:app --host 0.0.0.0 --port 8000
# test
curl http://localhost:8000/health


# Example prediction (build JSON using processed CSV columns):

# get columns
head -n 1 data/processed/city_day_processed.csv
# craft JSON e.g.
curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" \
  -d '{"data": {"PM2.5": 150.0, "PM10": 220.0, "NO2": 40.0, "SO2": 10.0, "CO": 1.2, "O3": 5.0}}'


# Docker compose (serving + mlflow UI)

docker-compose up --build
# API: http://localhost:8000
# MLflow UI: http://localhost:5000


# Run tests

pytest -q

# How to use your RTX 3060 effectively (practical advice)

# Prefer training on GPU for LightGBM/XGBoost only if you have installed the GPU-enabled library successfully.

# Building LightGBM with GPU on Windows tends to be more painful; WSL2 (Ubuntu) is recommended because the cmake/make flow is easier and WSL2 supports GPU passthrough (Windows 11).

# If building is difficult, stick to CPU RandomForest (fast enough for this dataset) — your pipeline and monitoring remain identical.

# For reproducibility and portability, consider training locally (GPU) but exporting a CPU-friendly model artifact (e.g., convert LightGBM to joblib if possible or save a CPU-trained model for serving). The API Dockerfile above assumes a CPU model.joblib.